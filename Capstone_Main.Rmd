---
title: "User_Function"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r}
#Read data in individual files into df
#getwd()
library("data.table")
filelist <-list.files(path = "Files", pattern = ".csv", full.names = TRUE)
#filelist
temp <- lapply(filelist, fread, sep=",")
weatherdata <- rbindlist(temp)

#Create new date field in yyyymmdd formatt to line up with EIA data
weatherdata <- within(weatherdata, intdate <- as.integer(date.year)*10000 + as.integer(date.mon)*100 + as.integer(date.mday))
#head(weatherdata)
#narrow df to fields of interest
weatherdata <- weatherdata[,-c(1,3:5,7:14,17:45)] 
# remove rows that have a temperature value of -9999
weatherdata <-weatherdata[!(weatherdata$tempm == -9999),]
#head(weatherdata)
#New DF with weather data averaged by day
weatherdataAvg <- aggregate(weatherdata[, 1:4], list(weatherdata$intdate), FUN = function(x) mean(as.numeric(as.character(x))))
#head(weatherdataAvg)
# Write new DF data to csv
write.csv(weatherdataAvg, file = "Daily Weather Data.csv")
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
#API call for weather data
library(lubridate)
library(jsonlite)

d <- as.Date('20151202', format = '%Y%m%d')
for(i in 1:400){
 date(d) <- date(d) + 1
 intdate <-as.integer(format(date(d), "%Y%m%d"))
 url <-paste0("http://api.wunderground.com/api/337b40a1234484ca/history_",intdate,"/q/LA/Erath.json")
 #print(url)
 raw.result <- fromJSON(url,flatten = TRUE)
 df_weatherdata <- raw.result$history$observations
 
 #Copy the structure for the running df and empty it only for first iteration - it gets appended on subsequent passes
 # Not doing this - outputting to individual files
 #if(i == 1) {
  #    df_combined <- df_weatherdata[0,]
  #  }
 # Not using combined db because outputting to individual files
 #df_combined <-rbind(df_combined,df_weatherdata)
 #print(df_combined)
 #write.csv(df_combined,file = paste0("Files/NG spot price history_",intdate,".csv"))
 write.csv(df_weatherdata,file = paste0("Files/NG spot price history_",intdate,".csv"))
           
 Sys.sleep(5)
 }
#write.csv wipes out the file and does a complete rewrite on every execution

#this can be used to append but col names is a true or a false
 #write.table(df_combined, file = "NG spot price history1.csv", sep = ",", append = TRUE, quote = FALSE,
 # col.names = FALSE, row.names = FALSE)



```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
#Combine the 2 datasets together
library(dplyr)
spotpf_df <- read.csv("eiaapipull.csv", header=TRUE)
#Restrict spot prices to 2015 & 2016 to match data in weather file
spotpf_df <- subset(spotpf_df, Date >= 20150101 & Date <= 20161231, select=c(Date, SpotPrice))

weather_df <- read.csv("Daily Weather Data.csv", header=TRUE)
#Rename Date column in weather data
library("data.table")
setnames(weather_df,c("Group.1"),c("Date"))
#Remove rownumber 
weather_df$X <- NULL
head(weather_df)
combined_df <- left_join(spotpf_df, weather_df, by = c("Date" = "Date"))
# Write combined data file to csv
write.csv(combined_df, file = "CombinedDataSet.csv")

```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.


```{r}
#****Try out different models
ModelData <-read.csv("CombinedDataSet.csv")
#str(ModelData)
#summary(ModelData)
#Model1
Model1 <- lm(SpotPrice ~ tempm, data = ModelData)
summary(Model1)
#residuals
#Model1$residuals
SSE1 = sum(Model1$residuals ^ 2)
SSE1
#Model2
Model2 <- lm(SpotPrice ~ tempm + hum, data = ModelData)
summary(Model2)
#residuals
#Model2$residuals
SSE2 = sum(Model2$residuals ^ 2)
SSE2
#Model3
Model3 <- lm(SpotPrice ~ tempm + hum + pressurem + hum*pressurem, data = ModelData)
summary(Model3)
#residuals
#Model3$residuals
SSE3 = sum(Model3$residuals ^ 2)
SSE3
#Model4
Model4 <- lm(SpotPrice ~ tempm + pressurem, data = ModelData)
summary(Model4)
#residuals
#Model4$residuals
SSE4 = sum(Model4$residuals ^ 2)
SSE4
#Correlations
cor(ModelData)
#Plot the model - Model3 looks to be the best
plot(Model3)
plot(Model1)
```

```{r}
#****Generate test data and test model
library(lubridate)
library(jsonlite)

d <- as.Date('20161231', format = '%Y%m%d')
for(i in 1:360){
 date(d) <- date(d) + 1
 intdate <-as.integer(format(date(d), "%Y%m%d"))
 url <-paste0("http://api.wunderground.com/api/337b40a1234484ca/history_",intdate,"/q/LA/Erath.json")
 raw.result <- fromJSON(url,flatten = TRUE)
 df_weatherdata <- raw.result$history$observations
 write.csv(df_weatherdata,file = paste0("TestFiles/Weather_",intdate,".csv"))
 sys.sleep(5)
 }

#Read data in individual files into df
library("data.table")
filelist <-list.files(path = "TestFiles", pattern = ".csv", full.names = TRUE)
temp <- lapply(filelist, fread, sep=",")
weatherdata <- rbindlist(temp)
weatherdata <- within(weatherdata, intdate <- as.integer(date.year)*10000 + as.integer(date.mon)*100 + as.integer(date.mday))
weatherdata <- weatherdata[,-c(1,3:5,7:14,17:45)] 
weatherdata <-weatherdata[!(weatherdata$tempm == -9999),]
weatherdataAvg <- aggregate(weatherdata[, 1:4], list(weatherdata$intdate), FUN = function(x) mean(as.numeric(as.character(x))))
write.csv(weatherdataAvg, file = "Daily Weather Data Test.csv")

#Combine the 2 datasets together
library(dplyr)
spotpf_df <- read.csv("eiaapipull.csv", header=TRUE)
#Restrict spot prices to 2017 
spotpf_df <- subset(spotpf_df, Date >= 20170101 & Date <= 20171204, select=c(Date, SpotPrice))
weather_df <- read.csv("Daily Weather Data Test.csv", header=TRUE)
library("data.table")
setnames(weather_df,c("Group.1"),c("Date"))
weather_df$X <- NULL
combined_df <- left_join(spotpf_df, weather_df, by = c("Date" = "Date"))
write.csv(combined_df, file = "CombinedDataSetTest3.csv")
#Run predictions over test data
prediction <-predict(Model3,combined_df)
newoutput <-cbind(combined_df,prediction)
#write.csv(newoutput, file = "Prediction_output.csv")
#SSE - 188 too high?
prediction.sse <- sum((prediction -combined_df$SpotPrice)^2,na.rm = TRUE)
prediction.sse
```

```{r}
#pre-processing exercise
PPModelDF <-read.csv("CombinedDataSet.csv")
#drop sequence number and pressurei from selection
summary(PPModelDF[,2:7])
#install.packages("caret")
library(caret)
# calculate the pre-process parameters from the dataset
preprocessParams <- preProcess(PPModelDF[,2:7], method=c("center", "scale"))
# summarize transform parameters
#print(preprocessParams)
# transform the dataset using the parameters
transformed <- predict(preprocessParams, PPModelDF[,2:7])
# summarize the transformed dataset
summary(transformed)
#Build models using pre-processeddata
PPModel1 <- lm(SpotPrice ~ tempm, data = transformed)
summary(PPModel1)
#residuals
PPSSE1 = sum(PPModel1$residuals ^ 2)
PPSSE1
#Model 3 was the best model in the previous exercise- Rsquared is the same as expected, SSE is 4-5 times higher
PPModel3 <- lm(SpotPrice ~ tempm + hum + pressurem + hum*pressurem, data = transformed)
summary(PPModel3)
PPSSE3 = sum(PPModel3$residuals ^ 2)
PPSSE3
#Run predictions using pre-processed model
PPModelDF_Test <-read.csv("CombinedDataSetTest.csv")
summary(PPModelDF_Test)
predictionPP <-predict(PPModel3,PPModelDF_Test)
newoutput <-cbind(PPModelDF_Test,predictionPP)
write.csv(newoutput, file = "Prediction_output_PP.csv")


